{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import gc\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from astropy.io import fits\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy import units\n",
    "from astropy.wcs import WCS\n",
    "from astropy.nddata.utils import Cutout2D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from reproject import reproject_exact, reproject_adaptive, reproject_interp\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "from helper_funcs import save_input_image_with_header_to_fits, save_target_image_catalog_to_fits\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config Class\n",
    "\n",
    "Edit the parameters of this class to specify the data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "      ''' Set default values for configuration parameters'''\n",
    "\n",
    "      # The following lists have to be synchronized along the indices. However, positional permutations are allowed.\n",
    "      interp_pixscale_l = [1., 1., 1., 1., 1] # In arcseconds, for each image class\n",
    "      instr_noise_l = [14e-6, 2e-3, 2e-3, 2e-3, 0.]#[14e-6, 2e-3, 2e-3, 2e-3, 0.] #[14e-6, 3e-3, 3e-3, 3e-3, 0.] #[14e-6, 2e-3, 2e-3, 2e-3, 0.]# In Jy\n",
    "      fwhm_l = [5.7, 18.1, 24.9, 36.6, 7.9] # In arcseconds\n",
    "      class_names = [\"24\", \"250\", \"350\", \"500\", \"500SR\"] # Do not change names, permutations are allowed!\n",
    "      class_types = [\"input\", \"input\", \"input\", \"input\", \"target\"]\n",
    "\n",
    "      # Paths\n",
    "      parent_out_dir = r\"/mnt/d/SRHerschel500/data/processed\" #r\"/scratch/p317470/SRHerschel500/data/processed\" # r\"/scratch/p317470/SRHerschel500/data/processed\" #r\"/scratch-shared/dkoopmans\" #r\"E:\\SRHerschel500\\DATA\" # Output directory of Data, change if needed to\n",
    "      dataset_dir_name = \"dataset_samples\" # Directory name of generated dataset\n",
    "      dir_to_data_maps = r\"/mnt/d/SRHerschel500/data/raw/sim datamaps\" #r\"/scratch/p317470/SRHerschel500/data/raw/sim datamaps\" # #r\"/scratch/p317470/SRHerschel500/data/raw/sim datamaps\" #r\"/mnt/d/SRHerschel500/data/raw/sim datamaps\" #r\"/scratch-shared/dkoopmans/sim_datamaps\" #r\"E:\\SRHerschel500\\RAW DATA\\sim datamaps\" # Path to simulation datamaps\n",
    "\n",
    "      # Instrument information\n",
    "      instrument_l = [\"MIPS24\", \"SPIRE250\", \"SPIRE350\", \"SPIRE500\", \"SR_SPIRE500\"]\n",
    "      instrument_names = [\"Spitzer MIPS\", \"Herschel SPIRE\", \"Herschel SPIRE\", \"Herschel SPIRE\", \"SR Herschel SPIRE\"]\n",
    "\n",
    "      # Cutout dimensions\n",
    "      input_cutout_dims = (256, 256)\n",
    "      target_cutout_dims = (256, 256)\n",
    "\n",
    "      # Global Configuration for Training, Validation, and Testing (order is important)\n",
    "      # Has to sum to 1.0 and individual 0.0 ratios are not possible --> either use very small value or use gen_obs_data.py which is more general to generate a full (Test) set\n",
    "      split = [0.02, 0.02, 0.96]\n",
    "\n",
    "      # The code relies heavily on multiprocessing to provide the data in a timely matter\n",
    "      # By default, 3 cores should be used for interpolation and can not be changed. This is due to the high memory usage.\n",
    "      # However, on HPCs, this can be changed\n",
    "      # Here, N_CPU indicates number of cores to be used for cutout generation: I/O (FITs saving) and source pre-detection.\n",
    "      N_CPU = 10 # Number of cores available for multi processing, Usually TOTAL CORES - 1\n",
    "      N_CPU_INTERP = 6 # Number of cores for interpolation, CAUTION: memory explodes with the number of cores\n",
    "\n",
    "      # Do not change!\n",
    "      CRVAL_offset1 = 0.64\n",
    "      CRVAL_offset2 = 0.67"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "###  WORKING CLASS ###\n",
    "######################\n",
    "\n",
    "class ProcessDataSet():\n",
    "    def __init__(self, prefix):\n",
    "        self.prefix = prefix\n",
    "\n",
    "        self.fname = lambda idx: f\"{self.prefix}_\" + f\"{Config.instrument_l[idx]}\" + \"_smoothed_Jy_beam.fits\"\n",
    "        \n",
    "        # Configuration dictionary for generating cutouts\n",
    "        self.gen_cutout_config = {\"Training\": {\"color\": 'white', \"pos_center\": [], \"save_path\": None}, \n",
    "                             \"Validation\": {\"color\": 'orange', \"pos_center\": [], \"save_path\": None},\n",
    "                               \"Test\" : {\"color\": 'green', \"pos_center\": [], \"save_path\": None}}\n",
    "\n",
    "        # Final configurations\n",
    "        self.prepare_dirs()\n",
    "        self.configure_cutouts()\n",
    "\n",
    "    def prepare_dirs(self):\n",
    "        # Grab the current directory and prepare subdirectories\n",
    "        cdir = Config.parent_out_dir\n",
    "        self.fig_path = os.path.join(os.path.join(cdir, f\"{Config.dataset_dir_name} - PreProcFigs\"), self.prefix)\n",
    "        self.data_path = os.path.join(os.path.join(cdir, f\"{Config.dataset_dir_name}\"), self.prefix)\n",
    "        self.train_path = os.path.join(self.data_path, \"Train\")\n",
    "        self.val_path = os.path.join(self.data_path, \"Validation\")\n",
    "        self.test_path = os.path.join(self.data_path, \"Test\")\n",
    "\n",
    "        self.gen_cutout_config[\"Training\"][\"save_path\"] = self.train_path\n",
    "        self.gen_cutout_config[\"Validation\"][\"save_path\"] = self.val_path\n",
    "        self.gen_cutout_config[\"Test\"][\"save_path\"] = self.test_path\n",
    "\n",
    "        # First time object creation --> create DIRS for saving\n",
    "        if not os.path.isdir(os.path.join(cdir, f\"{Config.dataset_dir_name} - PreProcFigs\")):\n",
    "            os.mkdir(os.path.join(cdir, f\"{Config.dataset_dir_name} - PreProcFigs\"))\n",
    "        if not os.path.isdir(os.path.join(cdir, f\"{Config.dataset_dir_name}\")):\n",
    "            os.mkdir(os.path.join(cdir, f\"{Config.dataset_dir_name}\"))\n",
    "        if not os.path.isdir(self.fig_path):\n",
    "            os.mkdir(self.fig_path)\n",
    "        if not os.path.isdir(self.data_path):\n",
    "            os.mkdir(self.data_path)\n",
    "        if not os.path.isdir(self.train_path):\n",
    "            os.mkdir(self.train_path)\n",
    "        if not os.path.isdir(self.val_path):\n",
    "            os.mkdir(self.val_path)\n",
    "        if not os.path.isdir(self.test_path):\n",
    "            os.mkdir(self.test_path)\n",
    "\n",
    "        # class subdirs\n",
    "        for cl in Config.class_names:\n",
    "            train_FITS_path = os.path.join(self.train_path, f\"{cl}\")\n",
    "            val_FITS_path = os.path.join(self.val_path, f\"{cl}\")\n",
    "            test_FITS_path = os.path.join(self.test_path, f\"{cl}\")\n",
    "\n",
    "            if not os.path.isdir(train_FITS_path):\n",
    "                os.mkdir(train_FITS_path)\n",
    "            if not os.path.isdir(val_FITS_path):\n",
    "                os.mkdir(val_FITS_path)\n",
    "            if not os.path.isdir(test_FITS_path):\n",
    "                os.mkdir(test_FITS_path)\n",
    "\n",
    "    def configure_cutouts(self):\n",
    "        # Load a temporary datamap\n",
    "        hdu = fits.open(os.path.join(Config.dir_to_data_maps, self.fname(0)), memmap=False)\n",
    "        hdr = hdu[0].header\n",
    "\n",
    "        # Calculate the distance between the centers of adjacent cutouts\n",
    "        DISTANCE_BETWEEN_CENTERS = (Config.input_cutout_dims[0]*Config.interp_pixscale_l[0])/3600 # degrees\n",
    "        \n",
    "        START_X = hdr[\"CRVAL1\"] - Config.CRVAL_offset1\n",
    "        END_X = hdr[\"CRVAL1\"] + Config.CRVAL_offset2\n",
    "        START_Y = hdr[\"CRVAL2\"] - Config.CRVAL_offset1\n",
    "        END_Y = hdr[\"CRVAL2\"] + Config.CRVAL_offset2\n",
    "\n",
    "        ra_l = np.arange(START_X, END_X, DISTANCE_BETWEEN_CENTERS)\n",
    "        dec_l = np.arange(START_Y, END_Y, DISTANCE_BETWEEN_CENTERS)\n",
    "\n",
    "        self.cutout_center_l = [SkyCoord(ra*units.degree, dec*units.degree, frame=\"fk5\") for ra in ra_l for dec in dec_l]\n",
    "        indices = np.arange(0, len(self.cutout_center_l), 1).tolist()\n",
    "        # Pre-computed training, validation and testing split\n",
    "        train_indices, test_val_indices = train_test_split(indices, test_size=Config.split[1] + Config.split[2], random_state=10)\n",
    "        val_indices, test_indices = train_test_split(test_val_indices, test_size=Config.split[2]/(Config.split[1] + Config.split[2]), random_state=10)\n",
    "\n",
    "        self.gen_cutout_config[\"Training\"][\"pos_center\"] = [self.cutout_center_l[i] for i in train_indices]\n",
    "        self.gen_cutout_config[\"Validation\"][\"pos_center\"] = [self.cutout_center_l[i] for i in val_indices]\n",
    "        self.gen_cutout_config[\"Test\"][\"pos_center\"] = [self.cutout_center_l[i] for i in test_indices]\n",
    "\n",
    "    def interp_datamaps(self, datamaps, original_header, interp_pixscale):\n",
    "        # Copy header\n",
    "        new_header = original_header.copy()\n",
    "\n",
    "        # Compute scaling\n",
    "        original_pix_scale = abs(original_header[\"CDELT1\"] * 3600)\n",
    "        scaler = original_pix_scale / interp_pixscale\n",
    "\n",
    "        # Update header with rescaled WCS\n",
    "        w_hdu = WCS(original_header)\n",
    "        new_hdr = w_hdu[::1/scaler, ::1/scaler].to_header()\n",
    "\n",
    "        for key in [\"CRPIX1\", \"CRPIX2\", \"CDELT1\", \"CDELT2\"]:\n",
    "            new_header[key] = new_hdr[key]\n",
    "\n",
    "        new_header[\"NAXIS1\"] = int(np.round(original_header[\"NAXIS1\"] * scaler + 0.5))\n",
    "        new_header[\"NAXIS2\"] = int(np.round(original_header[\"NAXIS2\"] * scaler + 0.5))\n",
    "\n",
    "        # Interpolation using new header WCS\n",
    "        datamaps = reproject_exact((datamaps, original_header), new_header, parallel=Config.N_CPU_INTERP, return_footprint=False)\n",
    "        # datamaps = reproject_interp((datamaps, original_header), new_header, parallel=Config.N_CPU_INTERP, return_footprint=False, order='bilinear')\n",
    "\n",
    "        datamaps[np.isnan(datamaps)] = 0 # Regions outside the map set to 0.\n",
    "\n",
    "        interp_wcs = WCS(new_header) # Create a new WCS object\n",
    "        return interp_wcs, datamaps\n",
    "    \n",
    "    def add_noise(self, sigma_instr_noise, img_data):\n",
    "        noisy_img = img_data.copy() + np.random.normal(0, sigma_instr_noise, (img_data.shape[0],img_data.shape[1]))\n",
    "        return noisy_img\n",
    "    \n",
    "    def generate_cutouts(self, size, interp_datamap, interp_wcs, cl, cl_type, fwhm, pix_scale, purpose, ax, augment_ID = 0, img_ID_iter = 0):\n",
    "        # Get the Training/Validation/Testing config\n",
    "        config = self.gen_cutout_config.get(purpose, \"Training\")\n",
    "\n",
    "        # Spawn daemon processes for fast post-processing and FITS saving\n",
    "        executor = ProcessPoolExecutor(max_workers=Config.N_CPU)\n",
    "\n",
    "        futures = []\n",
    "\n",
    "        for pos in config[\"pos_center\"]:\n",
    "            # Make cutout based on given center\n",
    "            cutout = Cutout2D(interp_datamap, position=pos, size=size, wcs=interp_wcs, mode=\"strict\", copy=True)\n",
    "\n",
    "            # Cutout projection on datamap\n",
    "            if ax is not None:\n",
    "                cutout.plot_on_original(color=config[\"color\"], ax=ax, alpha=0.8)\n",
    "\n",
    "            # Post-processing and disk saving\n",
    "            # Execute the queue'd jobs\n",
    "            if cl_type != \"target\":\n",
    "                future = executor.submit(save_input_image_with_header_to_fits, cutout.data, img_ID_iter, cl, cutout.wcs, config['save_path'])\n",
    "            else:\n",
    "                future = executor.submit(save_target_image_catalog_to_fits, cutout.data, img_ID_iter, cl, pix_scale, fwhm, cutout.wcs, purpose, config['save_path'])\n",
    "\n",
    "            futures.append(future)\n",
    "\n",
    "            # Increase the file number\n",
    "            img_ID_iter += 1\n",
    "        \n",
    "        # confirm the closure of all jobs\n",
    "        _ = [future.result() for future in futures]\n",
    "        executor.shutdown(cancel_futures=True) # ensure proper shutdown\n",
    "        return img_ID_iter\n",
    "\n",
    "    def run(self):\n",
    "        # List of datamaps with 15 x 15 arcminute coverage\n",
    "        self.fov_interp_cutout_list = []\n",
    "        self.fov_original_cutout_list = []\n",
    "\n",
    "        # We process the data maps one by one. Only the first one will be used for validation, Testing.\n",
    "        # The other maps are used for augmented training samples\n",
    "        for idx, cl in enumerate(Config.class_names):\n",
    "            # Load the map\n",
    "            hdu = fits.open(os.path.join(Config.dir_to_data_maps, self.fname(idx)), memmap=False)\n",
    "            original_size = int(np.round(Config.input_cutout_dims[0]*Config.interp_pixscale_l[idx]/(hdu[0].header[\"CDELT1\"]*3600)))\n",
    "            datamaps_w_noise = self.add_noise(Config.instr_noise_l[idx], hdu[0].data)\n",
    "            if Config.class_types[idx] != \"target\":\n",
    "                interp_wcs, interp_datamaps_w_noise = self.interp_datamaps(datamaps_w_noise, hdu[0].header, Config.interp_pixscale_l[idx])\n",
    "                size = Config.input_cutout_dims\n",
    "            else:\n",
    "                # We do not have to interpolate the target class\n",
    "                interp_wcs = WCS(hdu[0].header)\n",
    "                interp_datamaps_w_noise = datamaps_w_noise\n",
    "                size = Config.target_cutout_dims\n",
    "\n",
    "            img_ID_iter = 0\n",
    "            # Create a figure cutout overlay, to verify correct Training/Val/Test split for each class\n",
    "            # Only do this for the first datamap, which will not be augmented and hence also used for validation and Testing\n",
    "            # THEREFORE; augment_ID = 0 means NO AUGMENTATION\n",
    "            # img_ID_iter tracks the file ID number for saving FITS files.\n",
    "            fig_cutout_overlay, ax = self.create_cutout_projection_figure(interp_datamaps_w_noise, interp_wcs, idx)\n",
    "            img_ID_iter = self.generate_cutouts(size, interp_datamaps_w_noise, interp_wcs, cl, Config.class_types[idx], Config.fwhm_l[idx], Config.interp_pixscale_l[idx], \"Training\", ax, augment_ID = i, img_ID_iter = img_ID_iter)\n",
    "            _ = self.generate_cutouts(size, interp_datamaps_w_noise, interp_wcs, cl, Config.class_types[idx], Config.fwhm_l[idx], Config.interp_pixscale_l[idx], \"Validation\", ax, augment_ID = i, img_ID_iter = 0)\n",
    "            _ = self.generate_cutouts(size, interp_datamaps_w_noise, interp_wcs, cl, Config.class_types[idx], Config.fwhm_l[idx], Config.interp_pixscale_l[idx], \"Test\", ax, augment_ID = i, img_ID_iter = 0)\n",
    "            \n",
    "            # This is used for a Sample Mosaic plot showing pre-processing vs Post-processing\n",
    "            self.fov_interp_cutout_list.append(Cutout2D(interp_datamaps_w_noise, position=self.cutout_center_l[0], size=size, wcs=interp_wcs, mode=\"strict\"))\n",
    "            self.fov_original_cutout_list.append(Cutout2D(hdu[0].data, position=self.cutout_center_l[0], size=(original_size, original_size), wcs=WCS(hdu[0].header), mode=\"strict\"))\n",
    "\n",
    "            # Save the cutout overlay figure\n",
    "            ax.coords[0].set_format_unit('deg')\n",
    "\n",
    "            fig_cutout_overlay.savefig(f\"{self.fig_path}\" + f\"/CutoutPlot_On_Original_{cl}.pdf\", dpi=300)\n",
    "            plt.close(fig_cutout_overlay)\n",
    "\n",
    "            # Clear memory\n",
    "            gc.collect()\n",
    "\n",
    "        # Mosaic Plot\n",
    "        self.class_mosaic_plot()\n",
    "\n",
    "    def create_cutout_projection_figure(self, data_map, w_data_map, idx):\n",
    "        # Initiate figure for cutout projection\n",
    "        fig_cutout_overlay = plt.figure(figsize=(10,10))\n",
    "        ax = fig_cutout_overlay.add_subplot(111, projection=w_data_map)\n",
    "\n",
    "        if Config.class_names[idx] == \"24\":\n",
    "            im_ax = ax.imshow(np.array(data_map) * 1000, cmap=\"viridis\", vmin=0, vmax=1)\n",
    "        elif Config.class_names[idx] == \"500SR\":\n",
    "            im_ax = ax.imshow(np.array(data_map) * 1000, cmap=\"viridis\", vmin=0, vmax=25)\n",
    "        else:\n",
    "            im_ax = ax.imshow(np.array(data_map) * 1000, cmap=\"viridis\", vmin=0, vmax=60)\n",
    "\n",
    "        ax.set_ylabel(\"DEC (deg)\", fontsize=10)\n",
    "        ax.set_xlabel(\"RA (deg)\", fontsize=10)\n",
    "        \n",
    "        ax.tick_params()\n",
    "        white_box = patches.Rectangle((0.01, 0.01), 0.45, 0.05, linewidth=1.5, edgecolor='#414a4c', facecolor='white', transform=ax.transAxes, zorder=10)\n",
    "        ax.add_patch(white_box)\n",
    "\n",
    "        if Config.class_types[idx] != \"target\":\n",
    "            text_content = rf\"{Config.instrument_names[idx]} {Config.class_names[idx]}$\\mu m$\"\n",
    "        else:\n",
    "            text_content = rf\"{Config.instrument_names[idx]} {500}$\\mu m$\"\n",
    "\n",
    "        ax.text(0.05, 0.03, text_content, color='#414a4c', transform=ax.transAxes, ha='left', va='center', fontsize=16, zorder=11)\n",
    "        cax = fig_cutout_overlay.add_axes([ax.get_position().x1+0.02, ax.get_position().y0, 0.03, ax.get_position().y1 - ax.get_position().y0])  # Adjust the position of the colorbar if needed\n",
    "        cbar = fig_cutout_overlay.colorbar(im_ax, cax=cax)\n",
    "        cbar.set_label('mJy/beam', fontsize=10)\n",
    "        cbar.ax.tick_params(labelsize=8)\n",
    "\n",
    "        return fig_cutout_overlay, ax\n",
    "\n",
    "\n",
    "    def class_mosaic_plot(self):\n",
    "        dataset = \"SPRITZ\" if \"SPRITZ\" in self.prefix else (\"SIDES\" if \"SIDES\" in self.prefix else \"SHARK\")\n",
    "        bands = [f\"{band} μm\" if band != \"500SR\" else f\"SR 500 μm\" for band in Config.class_names]\n",
    "        fov = '256\" × 256\"'\n",
    "\n",
    "        data = {'before': [d.data for d in self.fov_original_cutout_list], \n",
    "                'after': [d.data for d in self.fov_interp_cutout_list]\n",
    "        }\n",
    "\n",
    "        # Plotting\n",
    "        fig, axes = plt.subplots(nrows=2, ncols=5, figsize=(15, 6))  # 2 rows for before and after, 5 columns for bands\n",
    "\n",
    "        # Configure the figure\n",
    "        fig.subplots_adjust(wspace=0.01, hspace=0.05)\n",
    "\n",
    "        # Plot the data\n",
    "        for process_idx, process in enumerate(['before', 'after']):\n",
    "            for col, (band, ax) in enumerate(zip(bands, axes[process_idx])):\n",
    "                if col == 0:\n",
    "                    im = ax.imshow(data[process][col]*1000, cmap='afmhot', vmin=0, vmax=1)\n",
    "                elif col >0 and col <4:\n",
    "                    im = ax.imshow(data[process][col], cmap='afmhot', vmin=0, vmax=50/1000)\n",
    "                else:\n",
    "                    im = ax.imshow(data[process][col], cmap='afmhot', vmin=0, vmax=10/1000)\n",
    "                ax.text(0.05, 0.95, f'{band}\\nFov: {fov}', color='white', fontsize=10, ha='left', va='top', transform=ax.transAxes, bbox=dict(facecolor='black', alpha=0.5))\n",
    "                ax.axis('off')\n",
    "\n",
    "                # Adding process label on the left side\n",
    "                if col == 0:\n",
    "                    ax.text(-0.68, 0.5, f'{dataset} ({process})', va='center', ha='left', fontsize=12, transform=ax.transAxes, weight='bold')\n",
    "\n",
    "        # Adjusting colorbars with equal width\n",
    "        cbar_width = 0.015\n",
    "\n",
    "        # Adding colorbars for 24 μm and SR 500 μm\n",
    "        cbar_24 = fig.colorbar(axes[0][0].images[0], ax=[axes[i][0] for i in range(2)], orientation='horizontal', pad=0.01, aspect=30, fraction=cbar_width)\n",
    "        cbar_24.set_label('mJy/beam')\n",
    "\n",
    "        # 250/350/500 micron colorbar shared across the columns\n",
    "        # We will use the `cbar_width` to maintain equal width of colorbars\n",
    "        # Adjust the `fraction` to maintain visual consistency\n",
    "        cbar_250_350_500 = fig.colorbar(axes[0][1].images[0], ax=[axes[0][1], axes[0][2], axes[0][3], axes[1][1], axes[1][2], axes[1][3]], orientation='horizontal', pad=0.01, aspect=80, fraction=cbar_width)\n",
    "        cbar_250_350_500.set_label('Jy/beam')\n",
    "\n",
    "        # SR 500 micron colorbar\n",
    "        cbar_sr_500 = fig.colorbar(axes[0][4].images[0], ax=[axes[i][4] for i in range(2)], orientation='horizontal', pad=0.01, aspect=30, fraction=cbar_width)\n",
    "        cbar_sr_500.set_label('Jy/beam')\n",
    "        fig.savefig(f\"{self.fig_path}\" + f\"/class_mosaic_plot.png\", dpi=300)\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WCSAXES =                    2 / Number of coordinate axes                      CRPIX1  =      2521.3901027104 / Pixel coordinate of reference point            CRPIX2  =      2521.2253880164 / Pixel coordinate of reference point            CDELT1  =  0.00027777777777778 / [deg] Coordinate increment at reference point  CDELT2  =  0.00027777777777778 / [deg] Coordinate increment at reference point  CUNIT1  = 'deg'                / Units of coordinate increment and value        CUNIT2  = 'deg'                / Units of coordinate increment and value        CTYPE1  = 'RA---TAN'           / Right ascension, gnomonic projection           CTYPE2  = 'DEC--TAN'           / Declination, gnomonic projection               CRVAL1  =                 20.7 / [deg] Coordinate value at reference point      CRVAL2  =                  0.7 / [deg] Coordinate value at reference point      LONPOLE =                180.0 / [deg] Native longitude of celestial pole       LATPOLE =                  0.7 / [deg] Native latitude of celestial pole        MJDREF  =                  0.0 / [d] MJD of fiducial time                       RADESYS = 'ICRS'               / Equatorial coordinate system                   END                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "##########################\n",
    "###  CODE IS RUN HERE ####\n",
    "##########################\n",
    "SHARK = [f\"SHARK_1\"] #[f\"SHARK_{}\" for i in range(4)]\n",
    "SIDES = [f\"SIDES_1\"]\n",
    "SPRITZ = [f\"SPRITZ\"]#[f\"SPRITZ\"]\n",
    "prefixes = SPRITZ + SHARK + SIDES  # Prefixes of the datamaps. Check the code for \"fname\" for details on standard formatting of files. CTRL + F --> \"fname\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for i, prefix in tqdm(enumerate(prefixes), desc=\"Processing...\", total=len(prefixes)):\n",
    "        ProcessDataSet(prefix).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
