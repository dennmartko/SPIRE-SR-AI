{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5021f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-19 17:58:05.037667: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-19 17:58:05.046775: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-19 17:58:05.060437: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-04-19 17:58:05.060480: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-19 17:58:05.070011: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-19 17:58:05.524319: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Input, Dense, LeakyReLU, Flatten, Conv2DTranspose\n",
    "\n",
    "class SpatialSelfAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_channels, name=None):\n",
    "        super(SpatialSelfAttention, self).__init__(name=name)\n",
    "\n",
    "        # Define linear transformations for queries, keys, and values\n",
    "        self.num_channels = num_channels\n",
    "\n",
    "        self.query_convs = tf.keras.layers.Conv2D(num_channels, kernel_size=1, data_format=\"channels_last\", strides=1)\n",
    "        self.key_convs = tf.keras.layers.Conv2D(num_channels, kernel_size=1, data_format=\"channels_last\", strides=1)\n",
    "        self.value_convs = tf.keras.layers.Conv2D(num_channels, kernel_size=1, data_format=\"channels_last\", strides=1)\n",
    "\n",
    "        # Define scaling factor for dot product\n",
    "        self.scale_factor = tf.math.sqrt(tf.cast(num_channels, dtype=tf.float32))\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        resh = tf.keras.layers.Reshape((inputs.shape[1] * inputs.shape[2], self.num_channels))\n",
    "        resh_final = tf.keras.layers.Reshape((inputs.shape[1], inputs.shape[2], self.num_channels))\n",
    "\n",
    "        q = resh(self.query_convs(inputs))\n",
    "        k = resh(self.key_convs(inputs))\n",
    "        v = resh(self.value_convs(inputs))\n",
    "\n",
    "        # dot-product attention\n",
    "        attention = tf.matmul(q, k, transpose_b=True) / self.scale_factor\n",
    "        attention = tf.keras.activations.softmax(attention)\n",
    "\n",
    "        # Calculate attention output\n",
    "        output = tf.matmul(attention,v)\n",
    "        output = resh_final(output)\n",
    "        return output\n",
    "    \n",
    "\n",
    "class ChannelSelfAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_channels, name=None):\n",
    "        super(ChannelSelfAttention, self).__init__(name=name)\n",
    "\n",
    "        # Define linear transformations for queries, keys, and values\n",
    "        self.num_channels = num_channels\n",
    "\n",
    "        self.query_convs = tf.keras.layers.Conv2D(num_channels, kernel_size=1, data_format=\"channels_last\", strides=1)\n",
    "        self.key_convs = tf.keras.layers.Conv2D(num_channels, kernel_size=1, data_format=\"channels_last\", strides=1)\n",
    "        self.value_convs = tf.keras.layers.Conv2D(num_channels, kernel_size=1, data_format=\"channels_last\", strides=1)\n",
    "\n",
    "        # Define scaling factor for dot product\n",
    "        self.scale_factor = tf.math.sqrt(tf.cast(num_channels, dtype=tf.float32))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Reshape for each head\n",
    "        resh = tf.keras.layers.Reshape((self.num_channels, inputs.shape[1] * inputs.shape[2]))\n",
    "        # Final reshape layer\n",
    "        out_resh = tf.keras.layers.Reshape((inputs.shape[1], inputs.shape[2], self.num_channels))\n",
    "\n",
    "        q = resh(self.query_convs(inputs))\n",
    "        k = resh(self.key_convs(inputs))\n",
    "        v = resh(self.value_convs(inputs))\n",
    "\n",
    "        # dot-product attention\n",
    "        attention = tf.matmul(q, k, transpose_b=True) / self.scale_factor\n",
    "        attention = tf.keras.activations.softmax(attention)\n",
    "\n",
    "        # Calculate attention output\n",
    "        output = tf.matmul(attention, v)\n",
    "        output = out_resh(output)\n",
    "        return output\n",
    "\n",
    "class PCAM(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_channels, ID, axis, data_format, name=None):\n",
    "        super(PCAM, self).__init__(name=name)\n",
    "\n",
    "        ## Scaling parameters\n",
    "        self.a = tf.Variable(initial_value=0.0, dtype=tf.float32, trainable=True, name=f\"a_{ID}\")\n",
    "        self.b = tf.Variable(initial_value=0.0, dtype=tf.float32, trainable=True, name=f\"b_{ID}\")\n",
    "\n",
    "        # Layer arguments\n",
    "        self.ID = ID\n",
    "        self.axis = axis\n",
    "        self.data_format = data_format\n",
    "        self.num_channels = num_channels\n",
    "\n",
    "        # Layers\n",
    "        self.spat_att = SpatialSelfAttention(num_channels=num_channels, name=f\"PSA_{self.ID}\")\n",
    "        self.chan_att = ChannelSelfAttention(num_channels=num_channels, name=f\"CSA_{self.ID}\")\n",
    "\n",
    "    def call(self, inp):\n",
    "        ## Spatial Attention\n",
    "        x = self.spat_att(inp)\n",
    "\n",
    "        ## Channel Attention\n",
    "        y = self.chan_att(inp)  \n",
    "\n",
    "        ## Fusion\n",
    "        fusion_chan = tf.keras.layers.Add(name=f\"ChanFusion_{self.ID}\")([self.a*y, inp])\n",
    "        fusion_spat = tf.keras.layers.Add(name=f\"SpatFusion_{self.ID}\")([self.b*x, inp])\n",
    "        fusion = tf.keras.layers.Add(name=f\"Fusion_{self.ID}\")([fusion_spat, fusion_chan])\n",
    "        return fusion\n",
    "    \n",
    "class CAM(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_channels, ID, axis, data_format, name=None):\n",
    "        super(CAM, self).__init__(name=name)\n",
    "\n",
    "        ## Scaling parameters\n",
    "        self.a = tf.Variable(initial_value=0.0, dtype=tf.float32, trainable=True, name=f\"a_{ID}\")\n",
    "\n",
    "        # Layer arguments\n",
    "        self.ID = ID\n",
    "        self.axis = axis\n",
    "        self.data_format = data_format\n",
    "        self.num_channels = num_channels\n",
    "\n",
    "        # Layers\n",
    "        self.chan_att = ChannelSelfAttention(num_channels=num_channels, name=f\"CSA_{self.ID}\")\n",
    "\n",
    "    def call(self, inp):\n",
    "        ## Channel Attention\n",
    "        x = self.chan_att(inp)\n",
    "\n",
    "        ## Fusion\n",
    "        fusion = tf.keras.layers.Add(name=f\"ChanFusion_{self.ID}\")([self.a*x, inp])\n",
    "        \n",
    "        return fusion\n",
    "    \n",
    "class Upsample(tf.keras.layers.Layer):\n",
    "    def __init__(self, deconv_params, r):\n",
    "        super(Upsample, self).__init__()\n",
    "\n",
    "        # Layer arguments\n",
    "        self.deconv_params = deconv_params.copy()\n",
    "        self.deconv_params[\"filters\"] = deconv_params[\"filters\"]*r**2 # Increase the number of channels since we need HxWxCr^2 --> HrxWrxC\n",
    "        self.r = r\n",
    "\n",
    "        # Layers\n",
    "        self.conv = Conv2D(**self.deconv_params, kernel_size=(3, 3), strides=(1,1))\n",
    "\n",
    "    def call(self, inp):\n",
    "        x = self.conv(inp)\n",
    "        x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "        x = tf.nn.depth_to_space(x, self.r, data_format=\"NHWC\")\n",
    "        return x\n",
    "\n",
    "def StemBlock(conv_params, bn_params, inp):\n",
    "    x = Conv2D(**conv_params, kernel_size=(7, 7), strides=(1,1))(inp)\n",
    "    x = BatchNormalization(**bn_params)(x)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "    return x\n",
    "\n",
    "def Res32projBlock(conv_params, bn_params, inp):\n",
    "    res = inp\n",
    "\n",
    "    # First the F(x) path\n",
    "    x = Conv2D(**conv_params, kernel_size=(3, 3), strides=(2,2))(inp)\n",
    "    x = BatchNormalization(**bn_params)(x)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    x = Conv2D(**conv_params, kernel_size=(3, 3), strides=(1,1))(x)\n",
    "    x = BatchNormalization(**bn_params)(x)\n",
    "\n",
    "    # Residual path\n",
    "    res = Conv2D(**conv_params, kernel_size=(1, 1), strides=(2,2))(res)\n",
    "\n",
    "    x = tf.keras.layers.Add()([res, x])\n",
    "    x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "    return x\n",
    "\n",
    "def Res32Block(conv_params, bn_params, drop_params, inp):\n",
    "    # First the F(x) path\n",
    "    x = Conv2D(**conv_params, kernel_size=(3, 3), strides=(1,1))(inp)\n",
    "    x = BatchNormalization(**bn_params)(x)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    # Possible dropout\n",
    "    if drop_params[\"rate\"] > 0.:\n",
    "        x = tf.keras.layers.Dropout(**drop_params)(x)\n",
    "\n",
    "    x = Conv2D(**conv_params, kernel_size=(3, 3), strides=(1,1))(x)\n",
    "    x = BatchNormalization(**bn_params)(x)\n",
    "\n",
    "    x = tf.keras.layers.Add()([inp, x])\n",
    "    x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "    return x\n",
    "\n",
    "def EncoderBlock(conv_params, bn_params, drop_params, n, inp):\n",
    "    # First the downsampling\n",
    "    x = Res32projBlock(conv_params, bn_params, inp)\n",
    "\n",
    "    #Loop for Res32 blocks\n",
    "    for i in range(n):\n",
    "        x = Res32Block(conv_params, bn_params, drop_params, x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def DecoderBlock(conv_params, deconv_params, bn_params, inp):\n",
    "    x = Conv2D(**conv_params, kernel_size=(3, 3), strides=(1,1))(inp)\n",
    "    x = BatchNormalization(**bn_params)(x)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    x = Upsample(deconv_params, 2)(x) # x2 upsample\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "122e1ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def UnetResnet34Tr(shape, data_format, C1=64, multipliers=(1, 2, 4, 8)):\n",
    "    axis = 1 if shape[0] != shape[1] else 3\n",
    "    # Block parameters\n",
    "    shape = shape\n",
    "    conv_params = lambda n, regularize_bool: {'filters':n*C1, 'kernel_initializer':tf.keras.initializers.HeUniform, 'bias_initializer':'zeros', 'use_bias':True, 'padding':'same', 'data_format': data_format, 'kernel_regularizer':'l1_l2' if regularize_bool else None}\n",
    "\n",
    "    deconv_params = lambda n, pad, regularize_bool: {'filters':n*C1, 'kernel_initializer':tf.keras.initializers.HeUniform, 'bias_initializer':'zeros', 'use_bias':True, 'padding':'same', 'data_format': data_format, 'kernel_regularizer':'l1_l2' if regularize_bool else None}\n",
    "    \n",
    "    bn_params = {'momentum':0.9, 'epsilon':1e-6, 'axis':axis}\n",
    "    drop_params = lambda d: {'rate':d}\n",
    "\n",
    "    # Model Blocks\n",
    "    inp = Input(shape=shape)\n",
    "\n",
    "    x = StemBlock(conv_params(multipliers[0], False), bn_params, inp) # 256x256\n",
    "    skip_stem = CAM(num_channels=x.shape[axis], ID=0, axis=axis, data_format=data_format, name=f\"CAM_{0}\")(x)\n",
    "\n",
    "    #ENCODER BLOCKS\n",
    "    x = EncoderBlock(conv_params(multipliers[0], False), bn_params, drop_params(0.), 3, x) # 128x128\n",
    "    skip1 = CAM(num_channels=x.shape[axis], ID=1, axis=axis, data_format=data_format, name=f\"CAM_{1}\")(x)\n",
    "    x = EncoderBlock(conv_params(multipliers[1], False), bn_params, drop_params(0.), 4, x) # 64x64\n",
    "    skip2 = PCAM(num_channels=x.shape[axis], ID=2, axis=axis, data_format=data_format, name=f\"PCAM_{0}\")(x)\n",
    "    x = EncoderBlock(conv_params(multipliers[2], False), bn_params, drop_params(0.), 6, x) # 32x32\n",
    "    skip3 = PCAM(num_channels=x.shape[axis], ID=3, axis=axis, data_format=data_format, name=f\"PCAM_{1}\")(x)\n",
    "    x = EncoderBlock(conv_params(multipliers[3], False), bn_params, drop_params(0.), 3, x) # 16x16\n",
    "    skip4 = PCAM(num_channels=x.shape[axis], ID=4, axis=axis, data_format=data_format, name=f\"PCAM_{2}\")(x)\n",
    "    x = EncoderBlock(conv_params(multipliers[3], False), bn_params, drop_params(0.), 2, x) # 8x8\n",
    "    x = PCAM(num_channels=x.shape[axis], ID=5, axis=axis, data_format=data_format, name=f\"PCAM_{3}\")(x)\n",
    "\n",
    "    # # UPSAMPLE\n",
    "    x = Upsample(deconv_params(multipliers[3], False, False), r=2)(x) # 16x16\n",
    "\n",
    "    # # DECODER BLOCKS\n",
    "    x = tf.concat([x, skip4], axis=axis) # 16x16\n",
    "    x = DecoderBlock(conv_params(multipliers[3], False), deconv_params(multipliers[2], False, False), bn_params, x) # 32x32\n",
    "    x = tf.concat([x, skip3], axis=axis) # 32x32\n",
    "    x = DecoderBlock(conv_params(multipliers[2], False), deconv_params(multipliers[1], False, False), bn_params, x) # 64x64\n",
    "    x = tf.concat([x, skip2], axis=axis) # 64x64\n",
    "    x = DecoderBlock(conv_params(multipliers[1], False), deconv_params(multipliers[0], False, False), bn_params, x) # 128x128\n",
    "    x = tf.concat([x, skip1], axis=axis) # 128x128\n",
    "    x = DecoderBlock(conv_params(multipliers[0], False), deconv_params(multipliers[0], False, False), bn_params, x) # 256x256\n",
    "\n",
    "    # concat stem\n",
    "    x = tf.concat([x, skip_stem], axis=axis) # 256x256\n",
    "    \n",
    "    # # Conv - Conv - OUT\n",
    "    x = Conv2D(**conv_params(multipliers[0], False), kernel_size=(3, 3), strides=(1,1))(x) # 256x256\n",
    "    x = BatchNormalization(**bn_params)(x)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    out = Conv2D(filters=1, kernel_size=(3,3), strides=(1,1), use_bias=True, padding='same', data_format=data_format)(x)\n",
    "    out = tf.keras.activations.linear(out)\n",
    "    return tf.keras.Model(inp, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61ea81a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-19 17:58:06.197192: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-19 17:58:06.224154: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-19 17:58:06.224189: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-19 17:58:06.227361: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-19 17:58:06.227389: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-19 17:58:06.227400: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-19 17:58:06.312598: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-19 17:58:06.312638: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-19 17:58:06.312643: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2019] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-04-19 17:58:06.312665: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-19 17:58:06.312685: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13114 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Ti SUPER, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 256, 256, 4)]        0         []                            \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)             (None, 256, 256, 64)         12608     ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization (Batch  (None, 256, 256, 64)         256       ['conv2d[0][0]']              \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " leaky_re_lu (LeakyReLU)     (None, 256, 256, 64)         0         ['batch_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)           (None, 128, 128, 64)         36928     ['leaky_re_lu[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_1 (Bat  (None, 128, 128, 64)         256       ['conv2d_4[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 128, 128, 64)         0         ['batch_normalization_1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)           (None, 128, 128, 64)         36928     ['leaky_re_lu_1[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)           (None, 128, 128, 64)         4160      ['leaky_re_lu[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_2 (Bat  (None, 128, 128, 64)         256       ['conv2d_5[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " add (Add)                   (None, 128, 128, 64)         0         ['conv2d_6[0][0]',            \n",
      "                                                                     'batch_normalization_2[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 128, 128, 64)         0         ['add[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)           (None, 128, 128, 64)         36928     ['leaky_re_lu_2[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_3 (Bat  (None, 128, 128, 64)         256       ['conv2d_7[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 128, 128, 64)         0         ['batch_normalization_3[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)           (None, 128, 128, 64)         36928     ['leaky_re_lu_3[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_4 (Bat  (None, 128, 128, 64)         256       ['conv2d_8[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " add_1 (Add)                 (None, 128, 128, 64)         0         ['leaky_re_lu_2[0][0]',       \n",
      "                                                                     'batch_normalization_4[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 128, 128, 64)         0         ['add_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)           (None, 128, 128, 64)         36928     ['leaky_re_lu_4[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_5 (Bat  (None, 128, 128, 64)         256       ['conv2d_9[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_5 (LeakyReLU)   (None, 128, 128, 64)         0         ['batch_normalization_5[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)          (None, 128, 128, 64)         36928     ['leaky_re_lu_5[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_6 (Bat  (None, 128, 128, 64)         256       ['conv2d_10[0][0]']           \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " add_2 (Add)                 (None, 128, 128, 64)         0         ['leaky_re_lu_4[0][0]',       \n",
      "                                                                     'batch_normalization_6[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " leaky_re_lu_6 (LeakyReLU)   (None, 128, 128, 64)         0         ['add_2[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)          (None, 128, 128, 64)         36928     ['leaky_re_lu_6[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_7 (Bat  (None, 128, 128, 64)         256       ['conv2d_11[0][0]']           \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_7 (LeakyReLU)   (None, 128, 128, 64)         0         ['batch_normalization_7[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)          (None, 128, 128, 64)         36928     ['leaky_re_lu_7[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_8 (Bat  (None, 128, 128, 64)         256       ['conv2d_12[0][0]']           \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " add_3 (Add)                 (None, 128, 128, 64)         0         ['leaky_re_lu_6[0][0]',       \n",
      "                                                                     'batch_normalization_8[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " leaky_re_lu_8 (LeakyReLU)   (None, 128, 128, 64)         0         ['add_3[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)          (None, 64, 64, 128)          73856     ['leaky_re_lu_8[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_9 (Bat  (None, 64, 64, 128)          512       ['conv2d_16[0][0]']           \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_9 (LeakyReLU)   (None, 64, 64, 128)          0         ['batch_normalization_9[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)          (None, 64, 64, 128)          147584    ['leaky_re_lu_9[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)          (None, 64, 64, 128)          8320      ['leaky_re_lu_8[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_10 (Ba  (None, 64, 64, 128)          512       ['conv2d_17[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " add_4 (Add)                 (None, 64, 64, 128)          0         ['conv2d_18[0][0]',           \n",
      "                                                                     'batch_normalization_10[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " leaky_re_lu_10 (LeakyReLU)  (None, 64, 64, 128)          0         ['add_4[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)          (None, 64, 64, 128)          147584    ['leaky_re_lu_10[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_11 (Ba  (None, 64, 64, 128)          512       ['conv2d_19[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_11 (LeakyReLU)  (None, 64, 64, 128)          0         ['batch_normalization_11[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)          (None, 64, 64, 128)          147584    ['leaky_re_lu_11[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_12 (Ba  (None, 64, 64, 128)          512       ['conv2d_20[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " add_5 (Add)                 (None, 64, 64, 128)          0         ['leaky_re_lu_10[0][0]',      \n",
      "                                                                     'batch_normalization_12[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " leaky_re_lu_12 (LeakyReLU)  (None, 64, 64, 128)          0         ['add_5[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)          (None, 64, 64, 128)          147584    ['leaky_re_lu_12[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_13 (Ba  (None, 64, 64, 128)          512       ['conv2d_21[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_13 (LeakyReLU)  (None, 64, 64, 128)          0         ['batch_normalization_13[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)          (None, 64, 64, 128)          147584    ['leaky_re_lu_13[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_14 (Ba  (None, 64, 64, 128)          512       ['conv2d_22[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " add_6 (Add)                 (None, 64, 64, 128)          0         ['leaky_re_lu_12[0][0]',      \n",
      "                                                                     'batch_normalization_14[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " leaky_re_lu_14 (LeakyReLU)  (None, 64, 64, 128)          0         ['add_6[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)          (None, 64, 64, 128)          147584    ['leaky_re_lu_14[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_15 (Ba  (None, 64, 64, 128)          512       ['conv2d_23[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_15 (LeakyReLU)  (None, 64, 64, 128)          0         ['batch_normalization_15[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)          (None, 64, 64, 128)          147584    ['leaky_re_lu_15[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_16 (Ba  (None, 64, 64, 128)          512       ['conv2d_24[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " add_7 (Add)                 (None, 64, 64, 128)          0         ['leaky_re_lu_14[0][0]',      \n",
      "                                                                     'batch_normalization_16[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " leaky_re_lu_16 (LeakyReLU)  (None, 64, 64, 128)          0         ['add_7[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)          (None, 64, 64, 128)          147584    ['leaky_re_lu_16[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_17 (Ba  (None, 64, 64, 128)          512       ['conv2d_25[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_17 (LeakyReLU)  (None, 64, 64, 128)          0         ['batch_normalization_17[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)          (None, 64, 64, 128)          147584    ['leaky_re_lu_17[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_18 (Ba  (None, 64, 64, 128)          512       ['conv2d_26[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " add_8 (Add)                 (None, 64, 64, 128)          0         ['leaky_re_lu_16[0][0]',      \n",
      "                                                                     'batch_normalization_18[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " leaky_re_lu_18 (LeakyReLU)  (None, 64, 64, 128)          0         ['add_8[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)          (None, 32, 32, 256)          295168    ['leaky_re_lu_18[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_19 (Ba  (None, 32, 32, 256)          1024      ['conv2d_33[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_19 (LeakyReLU)  (None, 32, 32, 256)          0         ['batch_normalization_19[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)          (None, 32, 32, 256)          590080    ['leaky_re_lu_19[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)          (None, 32, 32, 256)          33024     ['leaky_re_lu_18[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_20 (Ba  (None, 32, 32, 256)          1024      ['conv2d_34[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " add_9 (Add)                 (None, 32, 32, 256)          0         ['conv2d_35[0][0]',           \n",
      "                                                                     'batch_normalization_20[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " leaky_re_lu_20 (LeakyReLU)  (None, 32, 32, 256)          0         ['add_9[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)          (None, 32, 32, 256)          590080    ['leaky_re_lu_20[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_21 (Ba  (None, 32, 32, 256)          1024      ['conv2d_36[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_21 (LeakyReLU)  (None, 32, 32, 256)          0         ['batch_normalization_21[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)          (None, 32, 32, 256)          590080    ['leaky_re_lu_21[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_22 (Ba  (None, 32, 32, 256)          1024      ['conv2d_37[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " add_10 (Add)                (None, 32, 32, 256)          0         ['leaky_re_lu_20[0][0]',      \n",
      "                                                                     'batch_normalization_22[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " leaky_re_lu_22 (LeakyReLU)  (None, 32, 32, 256)          0         ['add_10[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)          (None, 32, 32, 256)          590080    ['leaky_re_lu_22[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_23 (Ba  (None, 32, 32, 256)          1024      ['conv2d_38[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_23 (LeakyReLU)  (None, 32, 32, 256)          0         ['batch_normalization_23[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)          (None, 32, 32, 256)          590080    ['leaky_re_lu_23[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_24 (Ba  (None, 32, 32, 256)          1024      ['conv2d_39[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " add_11 (Add)                (None, 32, 32, 256)          0         ['leaky_re_lu_22[0][0]',      \n",
      "                                                                     'batch_normalization_24[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " leaky_re_lu_24 (LeakyReLU)  (None, 32, 32, 256)          0         ['add_11[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)          (None, 32, 32, 256)          590080    ['leaky_re_lu_24[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_25 (Ba  (None, 32, 32, 256)          1024      ['conv2d_40[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_25 (LeakyReLU)  (None, 32, 32, 256)          0         ['batch_normalization_25[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)          (None, 32, 32, 256)          590080    ['leaky_re_lu_25[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_26 (Ba  (None, 32, 32, 256)          1024      ['conv2d_41[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " add_12 (Add)                (None, 32, 32, 256)          0         ['leaky_re_lu_24[0][0]',      \n",
      "                                                                     'batch_normalization_26[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " leaky_re_lu_26 (LeakyReLU)  (None, 32, 32, 256)          0         ['add_12[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)          (None, 32, 32, 256)          590080    ['leaky_re_lu_26[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_27 (Ba  (None, 32, 32, 256)          1024      ['conv2d_42[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_27 (LeakyReLU)  (None, 32, 32, 256)          0         ['batch_normalization_27[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)          (None, 32, 32, 256)          590080    ['leaky_re_lu_27[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_28 (Ba  (None, 32, 32, 256)          1024      ['conv2d_43[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " add_13 (Add)                (None, 32, 32, 256)          0         ['leaky_re_lu_26[0][0]',      \n",
      "                                                                     'batch_normalization_28[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " leaky_re_lu_28 (LeakyReLU)  (None, 32, 32, 256)          0         ['add_13[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)          (None, 32, 32, 256)          590080    ['leaky_re_lu_28[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_29 (Ba  (None, 32, 32, 256)          1024      ['conv2d_44[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_29 (LeakyReLU)  (None, 32, 32, 256)          0         ['batch_normalization_29[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)          (None, 32, 32, 256)          590080    ['leaky_re_lu_29[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_30 (Ba  (None, 32, 32, 256)          1024      ['conv2d_45[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " add_14 (Add)                (None, 32, 32, 256)          0         ['leaky_re_lu_28[0][0]',      \n",
      "                                                                     'batch_normalization_30[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " leaky_re_lu_30 (LeakyReLU)  (None, 32, 32, 256)          0         ['add_14[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)          (None, 32, 32, 256)          590080    ['leaky_re_lu_30[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_31 (Ba  (None, 32, 32, 256)          1024      ['conv2d_46[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_31 (LeakyReLU)  (None, 32, 32, 256)          0         ['batch_normalization_31[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)          (None, 32, 32, 256)          590080    ['leaky_re_lu_31[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_32 (Ba  (None, 32, 32, 256)          1024      ['conv2d_47[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " add_15 (Add)                (None, 32, 32, 256)          0         ['leaky_re_lu_30[0][0]',      \n",
      "                                                                     'batch_normalization_32[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " leaky_re_lu_32 (LeakyReLU)  (None, 32, 32, 256)          0         ['add_15[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_54 (Conv2D)          (None, 16, 16, 512)          1180160   ['leaky_re_lu_32[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_33 (Ba  (None, 16, 16, 512)          2048      ['conv2d_54[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_33 (LeakyReLU)  (None, 16, 16, 512)          0         ['batch_normalization_33[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_55 (Conv2D)          (None, 16, 16, 512)          2359808   ['leaky_re_lu_33[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_56 (Conv2D)          (None, 16, 16, 512)          131584    ['leaky_re_lu_32[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_34 (Ba  (None, 16, 16, 512)          2048      ['conv2d_55[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " add_16 (Add)                (None, 16, 16, 512)          0         ['conv2d_56[0][0]',           \n",
      "                                                                     'batch_normalization_34[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " leaky_re_lu_34 (LeakyReLU)  (None, 16, 16, 512)          0         ['add_16[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_57 (Conv2D)          (None, 16, 16, 512)          2359808   ['leaky_re_lu_34[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_35 (Ba  (None, 16, 16, 512)          2048      ['conv2d_57[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_35 (LeakyReLU)  (None, 16, 16, 512)          0         ['batch_normalization_35[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_58 (Conv2D)          (None, 16, 16, 512)          2359808   ['leaky_re_lu_35[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_36 (Ba  (None, 16, 16, 512)          2048      ['conv2d_58[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " add_17 (Add)                (None, 16, 16, 512)          0         ['leaky_re_lu_34[0][0]',      \n",
      "                                                                     'batch_normalization_36[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " leaky_re_lu_36 (LeakyReLU)  (None, 16, 16, 512)          0         ['add_17[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_59 (Conv2D)          (None, 16, 16, 512)          2359808   ['leaky_re_lu_36[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_37 (Ba  (None, 16, 16, 512)          2048      ['conv2d_59[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_37 (LeakyReLU)  (None, 16, 16, 512)          0         ['batch_normalization_37[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_60 (Conv2D)          (None, 16, 16, 512)          2359808   ['leaky_re_lu_37[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_38 (Ba  (None, 16, 16, 512)          2048      ['conv2d_60[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " add_18 (Add)                (None, 16, 16, 512)          0         ['leaky_re_lu_36[0][0]',      \n",
      "                                                                     'batch_normalization_38[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " leaky_re_lu_38 (LeakyReLU)  (None, 16, 16, 512)          0         ['add_18[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_61 (Conv2D)          (None, 16, 16, 512)          2359808   ['leaky_re_lu_38[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_39 (Ba  (None, 16, 16, 512)          2048      ['conv2d_61[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_39 (LeakyReLU)  (None, 16, 16, 512)          0         ['batch_normalization_39[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_62 (Conv2D)          (None, 16, 16, 512)          2359808   ['leaky_re_lu_39[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_40 (Ba  (None, 16, 16, 512)          2048      ['conv2d_62[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " add_19 (Add)                (None, 16, 16, 512)          0         ['leaky_re_lu_38[0][0]',      \n",
      "                                                                     'batch_normalization_40[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " leaky_re_lu_40 (LeakyReLU)  (None, 16, 16, 512)          0         ['add_19[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_69 (Conv2D)          (None, 8, 8, 512)            2359808   ['leaky_re_lu_40[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_41 (Ba  (None, 8, 8, 512)            2048      ['conv2d_69[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_41 (LeakyReLU)  (None, 8, 8, 512)            0         ['batch_normalization_41[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_70 (Conv2D)          (None, 8, 8, 512)            2359808   ['leaky_re_lu_41[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_71 (Conv2D)          (None, 8, 8, 512)            262656    ['leaky_re_lu_40[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_42 (Ba  (None, 8, 8, 512)            2048      ['conv2d_70[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " add_20 (Add)                (None, 8, 8, 512)            0         ['conv2d_71[0][0]',           \n",
      "                                                                     'batch_normalization_42[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " leaky_re_lu_42 (LeakyReLU)  (None, 8, 8, 512)            0         ['add_20[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_72 (Conv2D)          (None, 8, 8, 512)            2359808   ['leaky_re_lu_42[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_43 (Ba  (None, 8, 8, 512)            2048      ['conv2d_72[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_43 (LeakyReLU)  (None, 8, 8, 512)            0         ['batch_normalization_43[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_73 (Conv2D)          (None, 8, 8, 512)            2359808   ['leaky_re_lu_43[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_44 (Ba  (None, 8, 8, 512)            2048      ['conv2d_73[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " add_21 (Add)                (None, 8, 8, 512)            0         ['leaky_re_lu_42[0][0]',      \n",
      "                                                                     'batch_normalization_44[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " leaky_re_lu_44 (LeakyReLU)  (None, 8, 8, 512)            0         ['add_21[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_74 (Conv2D)          (None, 8, 8, 512)            2359808   ['leaky_re_lu_44[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_45 (Ba  (None, 8, 8, 512)            2048      ['conv2d_74[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_45 (LeakyReLU)  (None, 8, 8, 512)            0         ['batch_normalization_45[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_75 (Conv2D)          (None, 8, 8, 512)            2359808   ['leaky_re_lu_45[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_46 (Ba  (None, 8, 8, 512)            2048      ['conv2d_75[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " add_22 (Add)                (None, 8, 8, 512)            0         ['leaky_re_lu_44[0][0]',      \n",
      "                                                                     'batch_normalization_46[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " leaky_re_lu_46 (LeakyReLU)  (None, 8, 8, 512)            0         ['add_22[0][0]']              \n",
      "                                                                                                  \n",
      " PCAM_3 (PCAM)               (None, 8, 8, 512)            1575938   ['leaky_re_lu_46[0][0]']      \n",
      "                                                                                                  \n",
      " upsample (Upsample)         (None, 16, 16, 512)          9439232   ['PCAM_3[0][0]']              \n",
      "                                                                                                  \n",
      " PCAM_2 (PCAM)               (None, 16, 16, 512)          1575938   ['leaky_re_lu_40[0][0]']      \n",
      "                                                                                                  \n",
      " tf.concat (TFOpLambda)      (None, 16, 16, 1024)         0         ['upsample[0][0]',            \n",
      "                                                                     'PCAM_2[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_83 (Conv2D)          (None, 16, 16, 512)          4719104   ['tf.concat[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_47 (Ba  (None, 16, 16, 512)          2048      ['conv2d_83[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_47 (LeakyReLU)  (None, 16, 16, 512)          0         ['batch_normalization_47[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " upsample_1 (Upsample)       (None, 32, 32, 256)          4719616   ['leaky_re_lu_47[0][0]']      \n",
      "                                                                                                  \n",
      " PCAM_1 (PCAM)               (None, 32, 32, 256)          394754    ['leaky_re_lu_32[0][0]']      \n",
      "                                                                                                  \n",
      " tf.concat_1 (TFOpLambda)    (None, 32, 32, 512)          0         ['upsample_1[0][0]',          \n",
      "                                                                     'PCAM_1[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_85 (Conv2D)          (None, 32, 32, 256)          1179904   ['tf.concat_1[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_48 (Ba  (None, 32, 32, 256)          1024      ['conv2d_85[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_48 (LeakyReLU)  (None, 32, 32, 256)          0         ['batch_normalization_48[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " upsample_2 (Upsample)       (None, 64, 64, 128)          1180160   ['leaky_re_lu_48[0][0]']      \n",
      "                                                                                                  \n",
      " PCAM_0 (PCAM)               (None, 64, 64, 128)          99074     ['leaky_re_lu_18[0][0]']      \n",
      "                                                                                                  \n",
      " tf.concat_2 (TFOpLambda)    (None, 64, 64, 256)          0         ['upsample_2[0][0]',          \n",
      "                                                                     'PCAM_0[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_87 (Conv2D)          (None, 64, 64, 128)          295040    ['tf.concat_2[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_49 (Ba  (None, 64, 64, 128)          512       ['conv2d_87[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_49 (LeakyReLU)  (None, 64, 64, 128)          0         ['batch_normalization_49[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " upsample_3 (Upsample)       (None, 128, 128, 64)         295168    ['leaky_re_lu_49[0][0]']      \n",
      "                                                                                                  \n",
      " CAM_1 (CAM)                 (None, 128, 128, 64)         12481     ['leaky_re_lu_8[0][0]']       \n",
      "                                                                                                  \n",
      " tf.concat_3 (TFOpLambda)    (None, 128, 128, 128)        0         ['upsample_3[0][0]',          \n",
      "                                                                     'CAM_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_89 (Conv2D)          (None, 128, 128, 64)         73792     ['tf.concat_3[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_50 (Ba  (None, 128, 128, 64)         256       ['conv2d_89[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_50 (LeakyReLU)  (None, 128, 128, 64)         0         ['batch_normalization_50[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " upsample_4 (Upsample)       (None, 256, 256, 64)         147712    ['leaky_re_lu_50[0][0]']      \n",
      "                                                                                                  \n",
      " CAM_0 (CAM)                 (None, 256, 256, 64)         12481     ['leaky_re_lu[0][0]']         \n",
      "                                                                                                  \n",
      " tf.concat_4 (TFOpLambda)    (None, 256, 256, 128)        0         ['upsample_4[0][0]',          \n",
      "                                                                     'CAM_0[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_91 (Conv2D)          (None, 256, 256, 64)         73792     ['tf.concat_4[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_51 (Ba  (None, 256, 256, 64)         256       ['conv2d_91[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_51 (LeakyReLU)  (None, 256, 256, 64)         0         ['batch_normalization_51[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_92 (Conv2D)          (None, 256, 256, 1)          577       ['leaky_re_lu_51[0][0]']      \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 67823051 (258.72 MB)\n",
      "Trainable params: 67795787 (258.62 MB)\n",
      "Non-trainable params: 27264 (106.50 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = UnetResnet34Tr(shape=(256, 256, 4), data_format='channels_last')\n",
    "model.build(input_shape=(None, 256, 256, 4))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0700924c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
